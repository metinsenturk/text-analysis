# News Analysis

## Introduction

Natural Language Processing (NLP) is a machine learning research area that make the computers to understand and process human language. For a human, any given text would be meaningful, but for a computer, things might get more basic or complicated while decyphering the language. NLP aims to perform text analysis as humans understand the language, therefore, it considers the hierarchical structure of language. Common examples of NLP applications will perfrom operations like text summarization, translation, named entity analysis, question anwsering, auto completion, relationship extraction, sentiment analysis, speech recognition and topic segmentation.

The creation fo this project is to go through the deep learning field and learn how to apply it in a NLP context. Knowing that deep learning models, compared to traditional machine largning, can perform really accurate, we are focused to understand more about it. But why applied to nlp? Because people communicate most everyhting in their own language: web search, advertisement, emails, social media, language translation, etc. So, most of the problems we can find in internet is related how people have relations with each other. Thats why to learn more about this behavior and know how to solve problems, we need to understand nlp.

In this project, we are aiming to apply some of the NLP methods into news arcticles. We will spesifically focus on topic modeling and text summarization. We will apply these techniques into news dataset and try to categorize and summarize the news. We will be working with two datasets.

- The first dataset is all the [posts](https://www.kaggle.com/hacker-news/hacker-news) from Y Combinator's social news website. It covers posts from 2006 to 2017. It is accesible through BigQuery and the size of the dataset is around 13.6 GB.

- The second dataset will be the [Reuters Corpora](https://trec.nist.gov/data/reuters/reuters.html). It has three collections (RCV1, RCV2, TRC2). We will be using the first collection, RCV1, which contains 810,000 English written news. The size of the dataset is around 2.5 GB and it is available through request from NIST.

As a final product, a command line application will be created and it will produce a summary with news category tags for any given text.

## Objectives

- Understand and apply NLP to the text datasets
- Learn topic modeling
- Learn text summerization
- Learn and apply machine learning under the project
- Learn and apply deep learning under the project

## Key Performance Indicators

- Complete documentation for every stage in NLP.

- Complete notebooks that are able to perform main topics that are covered under documentation.

- Ability to apply and compare different machine learning techniques.

- Achieving above 85% accuracy on test dataset with valid model metrics.

- Achieving above %90 accuracy with deep learning models.

- Dumping working models for both techniques.

- Having a project where a third person is able to install and setup the project in a timely fashion.

- Publishing the project in PyPI.

##Â Goals

Our goal is to create a python application that is able to apply topic modeling and text summarization to any given text file.